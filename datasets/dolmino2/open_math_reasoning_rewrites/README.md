## Overview

This folder contains supplementary documentation of the **OpenMathReasoning Rewrite Fullthoughts** mid-training data.

At a high level, we explored various strategies to synthetically rewrite thinking traces generated by reasoning models (e.g., `DeepSeek-R1`). The final **Fullthoughts** data represents our most performant rewrite strategy as empirically determined via microanneals. The `rewrite_prompts.py` file contains all rewrite prompts that we explored, including those that did not make it into our final mix.

Below, we detail (1) our sourcing for the raw reasoning traces, and (2) the various rewriting strategies we explored.

## Sourcing raw reasoning traces
We source reasoning traces from the `cot` subset of the `nvidia/OpenMathReasoning` dataset. The raw data contains reasoning traces generated by `DeepSeek-R1` and `QwQ-32B` in response to 306K unique mathematical problems sourced from the [AoPS forums](https://artofproblemsolving.com/community). Please see the [original paper](https://arxiv.org/abs/2504.16891) by Nvidia for more details.

The original data may contain multiple solution traces for each problem; we filter to only keep one unique solution per problem.


## Synthetically rewriting reasoning traces
We generate rewrites by prompting `GPT-4.1` with `temperature=0.7, max_tokens=16384` with each raw solution trace and a strategy-dependent rewrite prompt. We supply a json schema to GPT to ensure correct output formatting. 

Broadly speaking, we consider two classes of rewriting strategies: those designed to reduce verbosity of the raw traces and distill its core content, and those designed to convert the trace into a dialogue with additional useful information. In all our rewrites, we also prompt GPT to convert math unicode symbols (e.g., Ï€) to the corresponding LaTeX code (`$\pi$`). 

1. **Verbosity-reducing rewrites:**
At a surface glance, the raw reasoning traces generated by R1-style models are often (1) quite verbose, (2) contain seemingly useless reasoning paths (e.g., verifying a trivial fact), and (3) may try the same mistaken approach over and over. We thus sought to explore the degree to which these verbose behaviors are useful for downstream training.
We design spectrum of verbosity-reducing strategies, ranging from "more faithful to the original trace" to "keep only the core content."

2. **Synthetic dialogue rewrites:**
Motivated by [https://arxiv.org/pdf/2410.12881](https://arxiv.org/pdf/2410.12881), we attempted to inject additional useful information into the reasoning traces (such as useful cognitive meta-reasoning behaviors, see [https://arxiv.org/abs/2503.01307](https://arxiv.org/abs/2503.01307)) by converting them into synthetic dialogues.


### Verbosity-reducing strategies

In order from "most faithful to original trace" to "most distilled", we consider:

1. **Fullthoughts**: Only edit traces for improved clarity or flow (e.g., edit instances with a single token repeated over and over), keeping all reasoning paths contained in the original trace.

2. **Emphasize meta-reasoning**: Rewrite the trace to highlight specific desireable meta-reasoning strategies (error correction, self-verification, planning, etc.).

3. **Sleek**: Rewrite the trace to only include the key solution steps, removing the dead-end explorations and solution-irrelevant attempts.

### Synthetic dialogue rewrites

1. **Student Teacher Lecture**: Convert trace into a student-teacher dialogue where the teacher first gives an explanation of all relevant math concepts. Aimed to inject further information into the trace.
2. **Student Teacher Planning**: Convert trace into a student-teacher dialogue where a teacher guides a student in planning their steps to solve the problem. Aimed to emphasize the meta-reasoning capability of planning.
3. **Student Teacher Reformulation**: Convert trace into a student-teacher dialogue where a teacher guides a student in reformulating the problem into a more solveable form. Aimed to emphasize the meta-reasoning capability of reformulation.
4. **Student Student Error Correction**: Convert trace into a dialogue between two students working together to solve the problem, where each student identifies the errors of the other and prompts them to correct it. Aimed to emphasize the meta-reasoning capability of error correction.

